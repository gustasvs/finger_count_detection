{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBYf0MV88TCxgFwDGa+vbG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustasvs/finger_count_detection/blob/main/reformatted%20to%20run%20with%20google%20collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_not_train = True\n",
        "\n",
        "# hparams\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 50\n",
        "LR = 0.01\n",
        "\n",
        "# image params\n",
        "# image_size = 96 # [96, 128, 160, 192, 224]\n",
        "image_size = 42\n",
        "gray_scale = True"
      ],
      "metadata": {
        "id": "RX2h0zv6VgM0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtJjgmi9DHZ0",
        "outputId": "e393d9f0-486c-4627-b96e-61ec74ed2297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, Dropout, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "!pip install tensorflow_addons\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def flip_images(images):\n",
        "    flipped_images = []\n",
        "    for img in images:\n",
        "        flipped_images.append(img)\n",
        "        flipped_images.append(tf.image.flip_left_right(img))\n",
        "        flipped_images.append(tf.image.flip_up_down(img))\n",
        "        flipped_images.append(tf.image.flip_left_right(tf.image.flip_up_down(img)))\n",
        "    return flipped_images\n",
        "\n",
        "def scale_images(images):\n",
        "    scaled_images = []\n",
        "    scaling_factors = [1, 1.1, 1.2]\n",
        "    for img in images:\n",
        "        original_size = tf.shape(img)[:2]\n",
        "        for factor in scaling_factors:\n",
        "            new_size = tf.cast(tf.round(tf.cast(original_size, tf.float32) * factor), tf.int32)\n",
        "            scaled_img = tf.image.resize(img, new_size)\n",
        "            scaled_img = tf.image.resize_with_crop_or_pad(scaled_img, original_size[0], original_size[1])\n",
        "            scaled_images.append(scaled_img)\n",
        "    return scaled_images\n",
        "\n",
        "def color_jitter_images(images):\n",
        "    color_jittered_images = []\n",
        "    for img in images:\n",
        "        for _ in range(3):\n",
        "            color_jittered_img = tf.image.random_brightness(img, max_delta=0.2)\n",
        "            color_jittered_img = tf.image.random_contrast(color_jittered_img, lower=0.8, upper=1.2)\n",
        "            color_jittered_images.append(color_jittered_img)\n",
        "    return color_jittered_images\n",
        "\n",
        "\n",
        "def rotate_images(images):\n",
        "    rotated_images = []\n",
        "    for img in images:\n",
        "        rotated_images.append(img)\n",
        "        # rotated_images.append(tf.image.rot90(img, k=1))\n",
        "        # rotated_images.append(tf.image.rot90(img, k=3))\n",
        "    return rotated_images\n",
        "\n",
        "def preprocess_image(img, target_size=(700, 700), gray_scale=False, single=False):\n",
        "    original_shape = tf.cast(tf.shape(img)[:2], tf.float32)\n",
        "    min_edge = tf.reduce_min(original_shape)\n",
        "    # fix to counter rounding being unprecise\n",
        "    scale_factor = target_size[0] * 1.001 / min_edge\n",
        "    new_shape = tf.cast(tf.round(original_shape * scale_factor), tf.int32)\n",
        "    img = tf.image.resize(img, new_shape)\n",
        "    if gray_scale:\n",
        "        img = tf.image.rgb_to_grayscale(img)\n",
        "    img = img / 255.0\n",
        "\n",
        "    # handle case when we need to return single image\n",
        "    if single:\n",
        "        img = tf.image.resize_with_crop_or_pad(img, target_size[0], target_size[1])\n",
        "        return img\n",
        "\n",
        "    # step 1 crop images\n",
        "    cropped_images = []\n",
        "    shape = tf.shape(img)\n",
        "     # wider\n",
        "    if shape[0] < shape[1]:\n",
        "        for i in range(3):\n",
        "            start = (shape[1] - target_size[1]) // 2 * i\n",
        "            cropped_img = tf.image.crop_to_bounding_box(img, 0, start, target_size[0], target_size[1])\n",
        "            cropped_images.append(cropped_img)\n",
        "    # taller\n",
        "    else:\n",
        "        # Width of the image (height is greater than width)\n",
        "        width = shape[1]\n",
        "        square_size = width  # Since the square side length should be equal to the width\n",
        "\n",
        "        # Calculate the vertical center of the image\n",
        "        vertical_center = shape[0] // 2\n",
        "\n",
        "        # Start points for the three crops\n",
        "        start_points = [\n",
        "            max(0, vertical_center - square_size // 2),  # Center aligned\n",
        "            max(0, vertical_center - square_size),       # Center aligned with top touching center\n",
        "            min(shape[0] - square_size, vertical_center) # Center aligned with bottom touching center or at bottom\n",
        "        ]\n",
        "\n",
        "        for start in start_points:\n",
        "            cropped_img = tf.image.crop_to_bounding_box(img, start, 0, square_size, square_size)\n",
        "            cropped_images.append(cropped_img)\n",
        "\n",
        "    # take out random 1 from the cropped images\n",
        "    if len(cropped_images) > 2:\n",
        "        cropped_images.pop(random.randint(0, len(cropped_images) - 1))\n",
        "\n",
        "    preprocessed_images = scale_images(cropped_images)\n",
        "    preprocessed_images = flip_images(preprocessed_images)\n",
        "    preprocessed_images = color_jitter_images(preprocessed_images)\n",
        "    preprocessed_images = rotate_images(preprocessed_images)\n",
        "\n",
        "    return preprocessed_images\n",
        "\n",
        "\n",
        "import zipfile\n",
        "def preprocess_and_save_images(output_folder, target_size=(700, 700), gray_scale=False):\n",
        "    uploaded = files.upload()  # Allows users to upload a zip file\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.endswith('.zip'):\n",
        "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "                zip_ref.extractall('/content/')\n",
        "            os.remove(filename)\n",
        "\n",
        "    input_folder = '/content/'\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    elif len(os.listdir(output_folder)) > 0:\n",
        "        return len(os.listdir(output_folder))\n",
        "        for filename in os.listdir(output_folder):\n",
        "            os.remove(os.path.join(output_folder, filename))\n",
        "\n",
        "    filenames = [os.path.join(dp, f) for dp, dn, filenames in os.walk(input_folder) for f in filenames if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for filepath in filenames:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            img = tf.image.decode_jpeg(f.read())\n",
        "            preprocessed_images = preprocess_image(img, target_size, gray_scale)\n",
        "            for i, preprocessed_img in enumerate(preprocessed_images):\n",
        "                if gray_scale:\n",
        "                    preprocessed_img = tf.image.grayscale_to_rgb(preprocessed_img)\n",
        "                output_filename = os.path.join(output_folder, f'{os.path.basename(filepath).split(\".\")[0]}_{i}.jpg')\n",
        "                with open(output_filename, 'wb') as f:\n",
        "                    f.write(tf.image.encode_jpeg(tf.cast(preprocessed_img * 255, tf.uint8)).numpy())\n",
        "\n",
        "    return len(os.listdir(output_folder))\n",
        "\n",
        "\n",
        "def preprocessed_image_generator(folder_path, batch_size=32):\n",
        "    while True:\n",
        "        image_files = os.listdir(folder_path)  # List all files in the folder\n",
        "\n",
        "\n",
        "        labels = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
        "        label_groups = {1: [], 2: [], 3: [], 4: [], 5: []}\n",
        "        for filename in image_files:\n",
        "            label = int(filename.split('_')[0])\n",
        "            labels[label] += 1\n",
        "            label_groups[label].append(filename)\n",
        "\n",
        "        min_label = min(labels.values())\n",
        "\n",
        "        # print(labels)\n",
        "\n",
        "        # Normalize all groups to the same size (min_label) by undersampling\n",
        "        normalized_files = []\n",
        "        for label, files in label_groups.items():\n",
        "            if len(files) > min_label:\n",
        "                files = random.sample(files, min_label)\n",
        "            normalized_files.extend(files)\n",
        "\n",
        "        # Shuffle to randomize the order for each epoch\n",
        "        random.shuffle(normalized_files)\n",
        "\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for filename in normalized_files:\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            img = tf.io.read_file(image_path)\n",
        "            img = tf.image.decode_jpeg(img, channels=3)\n",
        "            img = tf.image.convert_image_dtype(img, tf.float32)  # Normalize the image to [0, 1]\n",
        "\n",
        "            # Extract label from filename or separate file\n",
        "            label = extract_label_from_filename(filename)\n",
        "\n",
        "            batch_images.append(img)\n",
        "            batch_labels.append(label)\n",
        "\n",
        "            # show iamge and print label\n",
        "            # print(label)\n",
        "            # plt.imshow(img)\n",
        "            # plt.show()\n",
        "\n",
        "            # Check if the batch is full\n",
        "            if len(batch_images) >= batch_size:\n",
        "                yield np.stack(batch_images, axis=0), np.stack(batch_labels, axis=0)\n",
        "                batch_images, batch_labels = [], []\n",
        "\n",
        "        # If there's any leftover data less than a full batch, yield it as well\n",
        "        if batch_images:\n",
        "            yield np.stack(batch_images, axis=0), np.stack(batch_labels, axis=0)\n",
        "\n",
        "def extract_label_from_filename(filename):\n",
        "    # example filename 3_92_2.jpg\n",
        "    label_part = filename.split('_')[0]\n",
        "    label = int(label_part)\n",
        "\n",
        "    one_hot_label = tf.one_hot(label - 1, depth=5)\n",
        "\n",
        "    return one_hot_label\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnw1PSljDQWP",
        "outputId": "68e80a53-0a7b-463b-c577-81236c4f8680"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MovingAverage:\n",
        "    def __init__(self, window_size=5):\n",
        "        self.window_size = window_size\n",
        "        self.predictions = []\n",
        "\n",
        "    def update(self, new_prediction):\n",
        "        if len(self.predictions) >= self.window_size:\n",
        "            self.predictions.pop(0)\n",
        "        self.predictions.append(new_prediction)\n",
        "\n",
        "    def get_average(self):\n",
        "        if not self.predictions:\n",
        "            return None\n",
        "        return np.mean(self.predictions, axis=0)\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    res = []\n",
        "    # exponentionally scale each\n",
        "    for i in x:\n",
        "        res.append(i * i)\n",
        "    res_max = max(res)\n",
        "    for i in range(len(res)):\n",
        "        res[i] = res[i] / res_max\n",
        "    return res\n",
        "\n",
        "def get_frame():\n",
        "    js = Javascript('''\n",
        "    async function getFrame() {\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'none';\n",
        "        document.body.appendChild(video);\n",
        "\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = 640;\n",
        "        canvas.height = 480;\n",
        "        const context = canvas.getContext('2d');\n",
        "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "        stream.getTracks().forEach(track => track.stop());\n",
        "        video.remove();\n",
        "\n",
        "        return canvas.toDataURL('image/jpeg', 0.8);\n",
        "    }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('getFrame()')\n",
        "    return data\n",
        "\n",
        "def data_uri_to_image(data_uri):\n",
        "    header, encoded = data_uri.split(',', 1)\n",
        "    data = b64decode(encoded)\n",
        "    img_array = np.frombuffer(data, dtype=np.uint8)\n",
        "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "    return img\n",
        "\n",
        "def video_interface(model, image_size):\n",
        "    fig, ax = plt.subplots()\n",
        "    bars = ax.bar(range(1, 6), np.zeros(5), color='gray', width=0.5)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_xticks(range(1, 6))\n",
        "    ax.set_xticklabels(range(1, 6))\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_yticks([])\n",
        "    plt.show(block=False)\n",
        "\n",
        "    prediction_smoothing = MovingAverage(window_size=15)\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            data = get_frame()\n",
        "            frame = data_uri_to_image(data)\n",
        "\n",
        "            processed_frame = preprocess_image(frame, (image_size, image_size), gray_scale=False, single=True)\n",
        "            prediction = model.predict(np.expand_dims(processed_frame, axis=0), verbose=0)[0]\n",
        "\n",
        "            print(prediction)\n",
        "            prediction = softmax(prediction)\n",
        "\n",
        "            prediction_smoothing.update(prediction)\n",
        "            prediction = prediction_smoothing.get_average()\n",
        "\n",
        "            highest_pred_index = np.argmax(prediction)\n",
        "            for i, (bar, pred) in enumerate(zip(bars, prediction)):\n",
        "                bar.set_height(pred)\n",
        "                bar.set_color('red' if i == highest_pred_index else 'black')\n",
        "\n",
        "            fig.canvas.draw()\n",
        "            fig.canvas.flush_events()\n",
        "\n",
        "            if isinstance(processed_frame, tf.Tensor):\n",
        "                processed_frame = processed_frame.numpy()  # Convert to NumPy array\n",
        "            if processed_frame.dtype != np.uint8:\n",
        "                processed_frame = (processed_frame * 255).astype(np.uint8)  # Adjust data type and range\n",
        "\n",
        "            # cv2_imshow(processed_frame)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    finally:\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "VLJ-J1EoUZpA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "\n",
        "    os.system(f'wget https://github.com/gustasvs/finger_count_detection/raw/main/model.h5 -O model.h5')\n",
        "\n",
        "    model = tf.keras.models.load_model('model.h5', custom_objects={'F1Score': F1Score(num_classes=5, average='macro')})\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_model(input_shape):\n",
        "\n",
        "    # base_pretrained_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    # base_pretrained_model.trainable = False\n",
        "\n",
        "    model = Sequential([\n",
        "        # base_pretrained_model,\n",
        "        # GlobalAveragePooling2D(),\n",
        "\n",
        "        # conv layers\n",
        "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # flatten for dense layers\n",
        "        Flatten(),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        # dense layers for classification\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(5, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    learning_rate_decay = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=LR,\n",
        "        decay_steps=10000,\n",
        "        decay_rate=0.96,\n",
        "        staircase=True\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "                optimizer=Adam(learning_rate=LR, beta_1=0.9, beta_2=0.98, epsilon=1e-9),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', F1Score(num_classes=5, average='macro')])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "_hXBJoBKDRz0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print-options for less clutter\n",
        "np.set_printoptions(suppress=True, precision=2)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "\n",
        "# load_not_train = True\n",
        "\n",
        "if load_not_train:\n",
        "    model = load_model()\n",
        "    print(\"model loaded\")\n",
        "    video_interface(model, 224) # image_size\n",
        "    sys.exit()\n",
        "\n",
        "\n",
        "input_shape = (image_size, image_size, 3 if gray_scale else 3)\n",
        "\n",
        "# Load datasets\n",
        "prprocessed_train_len = preprocess_and_save_images('rokas_train_preprocessed', target_size=(image_size, image_size), gray_scale=gray_scale)\n",
        "steps_per_epoch = prprocessed_train_len // BATCH_SIZE\n",
        "print(\"Preprocessed train images:\", prprocessed_train_len)\n",
        "\n",
        "processed_validation_len = preprocess_and_save_images('rokas_validate_preprocessed', target_size=(image_size, image_size), gray_scale=gray_scale)\n",
        "validation_steps = processed_validation_len // BATCH_SIZE\n",
        "print(\"Preprocessed validation images:\", processed_validation_len)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pr2McWUHFVLQ",
        "outputId": "13be52d5-b13a-46cc-865d-6a1ac2f2df17"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model loaded\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.78 0.22 0.   0.   0.  ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.77 0.23 0.   0.   0.  ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.82 0.18 0.   0.   0.  ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.01 0.07 0.26 0.17 0.48]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.75 0.24 0.   0.   0.  ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.98 0.02 0.   0.   0.  ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.   0.   0.14 0.25 0.61]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7  0.29 0.01 0.   0.01]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09 0.24 0.25 0.08 0.35]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.   0.   0.15 0.44 0.42]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.   0.   0.12 0.44 0.44]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.74 0.25 0.   0.   0.  ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function getFrame() {\n",
              "        const video = document.createElement('video');\n",
              "        video.style.display = 'none';\n",
              "        document.body.appendChild(video);\n",
              "\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "        canvas.width = 640;\n",
              "        canvas.height = 480;\n",
              "        const context = canvas.getContext('2d');\n",
              "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
              "        \n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "        video.remove();\n",
              "        \n",
              "        return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-5f65e0bc08df>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvideo_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# image_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-350e5a31a17e>\u001b[0m in \u001b[0;36mvideo_interface\u001b[0;34m(model, image_size)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_uri_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-350e5a31a17e>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     ''')\n\u001b[1;32m     50\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'getFrame()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: preprocessed_image_generator('rokas_train_preprocessed', batch_size=BATCH_SIZE),\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=((None, input_shape[0], input_shape[1], input_shape[2]), (None, 5))\n",
        ")\n",
        "validation_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: preprocessed_image_generator('rokas_validate_preprocessed', batch_size=BATCH_SIZE),\n",
        "    output_types=(tf.float32, tf.float32),\n",
        "    output_shapes=((None, input_shape[0], input_shape[1], input_shape[2]), (None, 5))\n",
        ")\n"
      ],
      "metadata": {
        "id": "LtrPib8kH3JQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = create_model(input_shape)\n",
        "\n",
        "# train\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_data=validation_dataset,\n",
        "                    validation_steps=validation_steps)\n",
        "\n",
        "# plot the training history\n",
        "if 'loss' in history.history:\n",
        "    plt.plot(history.history['loss'], label='train loss')\n",
        "if 'accuracy' in history.history:\n",
        "    plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "if 'val_loss' in history.history:\n",
        "    plt.plot(history.history['val_loss'], label='val loss')\n",
        "if 'val_f1_score' in history.history:\n",
        "    plt.plot(history.history['val_f1_score'], label='val F1 Score')\n",
        "\n",
        "plt.title('Training History')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "4LbjK-cLH6BX",
        "outputId": "4fcf9dfd-8e78-4eeb-f860-674372660882"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184716\n",
            "100/100 [==============================] - 99s 915ms/step - loss: 33.0331 - accuracy: 0.2031 - f1_score: 0.1500 - val_loss: 1.6114 - val_accuracy: 0.1813 - val_f1_score: 0.0614\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model using video interface aftert training\n",
        "video_interface(model, image_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "156hl8PEVrSL",
        "outputId": "c49d3557-314b-4117-abbf-cf9424402f14"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-5856d1916fb4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test the model using video interface aftert training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvideo_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-4aea43b8746d>\u001b[0m in \u001b[0;36mvideo_interface\u001b[0;34m(model, image_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# read frame from the camera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}